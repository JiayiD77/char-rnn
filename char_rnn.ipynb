{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, input_size)\n",
    "        self.rnn = nn.RNN(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          dropout=dropout)\n",
    "        self.decoder = nn.Linear(in_features=hidden_size,\n",
    "                                 out_features=output_size)\n",
    "        \n",
    "    def forward(self, x, hidden_state):\n",
    "        embeddings = self.embedding(x)\n",
    "        output, hidden_state = self.rnn(embeddings, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        return output, hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "Preparing training data......\n",
      "Total number of characters in the text is: 1115394\n",
      "Total number of unique characters is: 65\n",
      "The unique characters are: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text = open(\"input.txt\", 'r').read()\n",
    "chars = sorted(list(set(text)))\n",
    "data_size = len(text)\n",
    "vocab_size = len(chars)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Preparing training data......\")\n",
    "print(f\"Total number of characters in the text is: {data_size}\")\n",
    "print(f\"Total number of unique characters is: {vocab_size}\")\n",
    "print(f\"The unique characters are: {chars}\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "\n",
    "chars_to_ids = {c:i for i, c in enumerate(chars)}\n",
    "ids_to_chars = {i:c for i, c in enumerate(chars)}\n",
    "\n",
    "encode = lambda s:[chars_to_ids[c] for c in s]\n",
    "decode = lambda l:[ids_to_chars[i] for i in l]\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "split = int(0.9*len(data))\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]\n",
    "# train_data = torch.unsqueeze(data[:split], dim=1)\n",
    "# test_data = torch.unsqueeze(data[split:], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "hidden_size = 256\n",
    "seq_len = 128\n",
    "num_layers = 3\n",
    "dropout = 0\n",
    "lr = 1e-4\n",
    "epochs = 80\n",
    "test_seq_len = 5000\n",
    "\n",
    "# device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Available device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'hidden_size':[256],\n",
    "              'dropout':[0],\n",
    "              'lr':[1e-4],\n",
    "              'epoch':[100],\n",
    "              'num_layers':[1, 2, 3, 4, 5],\n",
    "              'seq_len':[128]\n",
    "              }\n",
    "param_grid = ParameterGrid(param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(param_dict, device, train_data, vocab_size, experiment_name):\n",
    "    \n",
    "    model = RNN(input_size=vocab_size,\n",
    "                hidden_size=param_dict['hidden_size'],\n",
    "                output_size=vocab_size,\n",
    "                num_layers=param_dict['num_layers'],\n",
    "                dropout=param_dict['dropout']).to(device)\n",
    "    \n",
    "    # Record experiment\n",
    "    log_dir = os.path.join('runs', experiment_name, 'num_layers', str(param_dict['num_layers']))\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    \n",
    "    model.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=param_dict['lr'])\n",
    "    train_data = train_data.to(device)\n",
    "\n",
    "    print(\"Training.....\")\n",
    "    for epoch in range(param_dict['epoch']):\n",
    "        start_idx = torch.randint(0, 200, (1,))\n",
    "        n = 0    \n",
    "        total_loss = 0\n",
    "        hidden_state = None\n",
    "        seq_len = param_dict['seq_len']\n",
    "        \n",
    "        while True:\n",
    "            input_seq = train_data[start_idx : start_idx+seq_len]\n",
    "            target_seq = train_data[start_idx+1 : start_idx+seq_len+1]\n",
    "            \n",
    "            output_seq, hidden_state = model(input_seq, hidden_state)\n",
    "            hidden_state = hidden_state.data\n",
    "            \n",
    "            loss = loss_fn(torch.squeeze(output_seq), torch.squeeze(target_seq))\n",
    "            total_loss += loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            start_idx += seq_len\n",
    "            n += 1\n",
    "            \n",
    "            if start_idx + seq_len + 1 > len(train_data) - 1:\n",
    "                break\n",
    "            \n",
    "        if epoch % 1 == 0:    \n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Loss: {total_loss/n:.5f}\") \n",
    "        \n",
    "        writer.add_scalars(main_tag='Train Loss', tag_scalar_dict={'train_loss':total_loss}, global_step=epoch)\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.....\n",
      "Epoch: 0\n",
      "Loss: 2.19266\n",
      "Training.....\n",
      "Epoch: 0\n",
      "Loss: 2.08227\n",
      "Training.....\n",
      "Epoch: 0\n",
      "Loss: 2.03990\n",
      "Training.....\n",
      "Epoch: 0\n",
      "Loss: 2.03145\n",
      "Training.....\n",
      "Epoch: 0\n",
      "Loss: 2.04331\n"
     ]
    }
   ],
   "source": [
    "for parameters in param_grid:\n",
    "    train(param_dict=parameters, device=device, train_data=train_data, vocab_size=vocab_size, experiment_name='Model_layer_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, test_seq_len, test_data):\n",
    "    \n",
    "    test_data = test_data.to(device)\n",
    "    print(\"Generating Texts.....\")\n",
    "\n",
    "    char_num = 0\n",
    "    hidden_state_gen = None\n",
    "    start_idx_gen = torch.randint(0, 200, (1,))\n",
    "    input_seq_gen = test_data[start_idx_gen : start_idx_gen+seq_len]\n",
    "    while True:\n",
    "        \n",
    "        input = input_seq_gen[-seq_len:]\n",
    "        output, hidden_state_gen = model(input, hidden_state_gen)\n",
    "        output = F.softmax(torch.squeeze(output[-1]), dim=0)\n",
    "        dist = Categorical(output)\n",
    "        index = dist.sample()\n",
    "        print(ids_to_chars[index.item()], end='')\n",
    "        \n",
    "        input_seq_gen = torch.cat((input_seq_gen, index.unsqueeze(dim=0)), dim=0)\n",
    "        char_num += 1\n",
    "        \n",
    "        if char_num > test_seq_len:\n",
    "            break\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(rnn, test_seq_len, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(rnn_3, 150, lr, device, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(rnn_3, test_seq_len, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import FashionMNIST, MNIST, CIFAR10\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..\\Data'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x * 255).type(torch.long))\n",
    "])\n",
    "train_data = FashionMNIST(root=path, train=True, download=True, transform=transform)\n",
    "test_data = FashionMNIST(root=path, train=False, download=True, transform=transform)\n",
    "# train_data = MNIST(root=path, train=True, download=True, transform=ToTensor())\n",
    "# test_data = MNIST(root=path, train=False, download=True, transform=ToTensor()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "for i in range(1, 10):\n",
    "    idx = torch.randint(0, len(train_data), (1,)).item()\n",
    "    img, label = train_data[idx]\n",
    "    fig.add_subplot(3, 3, i)\n",
    "    plt.imshow(img.squeeze())\n",
    "    plt.title(train_data.classes[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_flatten = torch.empty((1), dtype=torch.long)\n",
    "i = 1\n",
    "for x, _ in train_data_loader:\n",
    "    flattened = x.flatten()\n",
    "    train_data_flatten = torch.cat((train_data_flatten, flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0):\n",
    "        super(ImageRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, input_size)\n",
    "        self.rnn = nn.RNN(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          dropout=dropout)\n",
    "        self.decoder = nn.Linear(in_features=hidden_size,\n",
    "                                 out_features=output_size)\n",
    "        \n",
    "    def forward(self, x, hidden_state):\n",
    "        embeddings = self.embedding(x)\n",
    "        output, hidden_state = self.rnn(embeddings, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        return output, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgRNN = ImageRNN(input_size=256, \n",
    "                  hidden_size=512,\n",
    "                  output_size=256,\n",
    "                  num_layers=1,\n",
    "                  dropout=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(ImgRNN, epochs=40, lr=0.0003, device=device, train_data=train_data_flatten, seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
